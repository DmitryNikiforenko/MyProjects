{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "98262483",
      "metadata": {
        "id": "98262483"
      },
      "source": [
        "- Создать Dataset для загрузки данных (sklearn.datasets.fetch_california_housing)\n",
        "- Обернуть его в Dataloader\n",
        "- Написать архитектуру сети, которая предсказывает стоимость недвижимости. Сеть должна включать BatchNorm слои и Dropout (или НЕ включать, но нужно обосновать)\n",
        "- Сравните сходимость Adam, RMSProp и SGD, сделайте вывод по качеству работы модели\n",
        "- train-test разделение нужно сделать с помощью sklearn random_state=13, test_size = 0.25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8527a16d",
      "metadata": {
        "id": "8527a16d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam, RMSprop, SGD\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHES = 10\n",
        "LR = 0.002"
      ],
      "metadata": {
        "id": "9tPL7CybzeO7"
      },
      "id": "9tPL7CybzeO7",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FCHDataset(Dataset):\n",
        "  def __init__(self, *init_datasets):\n",
        "    assert all(init_datasets[0].size(0) == init_dataset.size(0) for init_dataset in init_datasets)\n",
        "    self._base_datasets = init_datasets\n",
        "\n",
        "  def __len__(self):\n",
        "    return self._base_datasets[0].size(0)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      return tuple(base_dataset[idx] for base_dataset in self._base_datasets)"
      ],
      "metadata": {
        "id": "b_IN14vlzxEC"
      },
      "id": "b_IN14vlzxEC",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CHNet(nn.Module):\n",
        "  def __init__(self) -> None:\n",
        "      super(CHNet, self).__init__()\n",
        "      self.block_1 = nn.Sequential(\n",
        "          nn.Linear(in_features=8, out_features=100, bias=True),\n",
        "          nn.Dropout(0.5),\n",
        "          nn.BatchNorm1d(100),\n",
        "          nn.LeakyReLU())\n",
        "      self.block_2 = nn.Sequential(\n",
        "          nn.Linear(in_features=100, out_features=100, bias=True),\n",
        "          nn.Dropout(0.5),\n",
        "          nn.BatchNorm1d(100),\n",
        "          nn.LeakyReLU())\n",
        "      self.block_3 = nn.Sequential(\n",
        "          nn.Linear(in_features=100, out_features=60, bias=True),\n",
        "          nn.Dropout(0.5),\n",
        "          nn.BatchNorm1d(60),\n",
        "          nn.LeakyReLU())\n",
        "      self.block_4 = nn.Sequential(\n",
        "          nn.Linear(in_features=60, out_features=30, bias=True),\n",
        "          nn.Dropout(0.5),\n",
        "          nn.BatchNorm1d(30),\n",
        "          nn.LeakyReLU())\n",
        "      self.predict = nn.Sequential(\n",
        "          nn.Linear(in_features=30, out_features=1, bias=True),\n",
        "          nn.BatchNorm1d(1),\n",
        "          nn.LeakyReLU())\n",
        "\n",
        "  def forward(self, inp):\n",
        "    out = self.block_1(inp)\n",
        "    out = self.block_2(out)\n",
        "    out = self.block_3(out)\n",
        "    out = self.block_4(out)\n",
        "    out = self.predict(out)\n",
        "    return out[:, 0]"
      ],
      "metadata": {
        "id": "570YHm300BPy"
      },
      "id": "570YHm300BPy",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(train_loader, test_loader, net, optimizer):\n",
        "  loss_fn = nn.MSELoss()\n",
        "  best_acc = {'train': None, 'test': None}\n",
        "  net.train()\n",
        "  for epoch in range(EPOCHES):\n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        running_items += len(labels)\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 100 == 0 or (i + 1) == len(train_loader):    # печатаем каждые 100 mini-batches\n",
        "            net.eval()\n",
        "\n",
        "            test_loss, test_running_total, test_loss  = 0.0, 0.0, 0.0\n",
        "            for y, (out_test, lbl_test) in enumerate(test_loader):\n",
        "                test_outputs = net(out_test)\n",
        "                test_loss += loss_fn(test_outputs, lbl_test)\n",
        "                test_running_total += len(lbl_test)\n",
        "\n",
        "            res_loss_train = running_loss / running_items\n",
        "            res_loss_test = test_loss / test_running_total\n",
        "\n",
        "            if best_acc['train'] is None or res_loss_train < best_acc['train']:\n",
        "              best_acc['train'] = res_loss_train\n",
        "\n",
        "            if best_acc['test'] is None or res_loss_test < best_acc['test']:\n",
        "              best_acc['test'] = res_loss_train\n",
        "\n",
        "            print(f'Epoch [{epoch + 1}/{EPOCHES}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {res_loss_train:.3f}. '\\\n",
        "                  f'Test acc: {res_loss_test:.3f}.')\n",
        "\n",
        "            running_loss, running_items = 0.0, 0.0\n",
        "            net.train()\n",
        "  print(f\"Best acc train: {1 - best_acc['train']:.3f}. Best acc test: {1 - best_acc['test']:.3f}\")\n",
        "  print('Training is finished!')"
      ],
      "metadata": {
        "id": "zV-4-yma0_Sp"
      },
      "id": "zV-4-yma0_Sp",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "california_housing = fetch_california_housing()\n",
        "# Разделим на тестовые и тренеровочные данные\n",
        "X_train, X_test, y_train, y_test = train_test_split(california_housing.data, california_housing.target, test_size=0.25, random_state=13)"
      ],
      "metadata": {
        "id": "MPPpjKmv1b_H"
      },
      "id": "MPPpjKmv1b_H",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Нормализуем данные и подготовим их для дальнейшего использования в нашем dstaset\n",
        "scale = MinMaxScaler()\n",
        "X_train_s = scale.fit_transform(X_train)\n",
        "X_test_s = scale.transform(X_test)"
      ],
      "metadata": {
        "id": "TySk3zC51dQ7"
      },
      "id": "TySk3zC51dQ7",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_xt = torch.from_numpy(X_train_s.astype(np.float32))\n",
        "train_yt = torch.from_numpy(y_train.astype(np.float32))\n",
        "\n",
        "test_xt = torch.from_numpy(X_test_s.astype(np.float32))\n",
        "test_yt = torch.from_numpy(y_test.astype(np.float32))"
      ],
      "metadata": {
        "id": "2Du2ylYg1f1V"
      },
      "id": "2Du2ylYg1f1V",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = FCHDataset(train_xt, train_yt)\n",
        "test_dataset = FCHDataset(test_xt, test_yt)"
      ],
      "metadata": {
        "id": "_g0qznJM1ie8"
      },
      "id": "_g0qznJM1ie8",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=True, num_workers=2, drop_last=True)"
      ],
      "metadata": {
        "id": "T-lY9sg31kPg"
      },
      "id": "T-lY9sg31kPg",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение моделей с lr = 0.002"
      ],
      "metadata": {
        "id": "SyxvPZES6Maw"
      },
      "id": "SyxvPZES6Maw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "SGD"
      ],
      "metadata": {
        "id": "eOEJVr7o2Hfh"
      },
      "id": "eOEJVr7o2Hfh"
    },
    {
      "cell_type": "code",
      "source": [
        "net = CHNet()\n",
        "optimizer = SGD(net.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "CAbVdUBs1_c1"
      },
      "id": "CAbVdUBs1_c1",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_loop(train_loader, test_loader, net, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv9jIphv2K_f",
        "outputId": "6786173d-2a2f-4cb9-fb0e-2d0c98120f81"
      },
      "id": "Hv9jIphv2K_f",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]. Step [1/120]. Loss: 0.038. Test acc: 0.042.\n",
            "Epoch [1/10]. Step [101/120]. Loss: 0.032. Test acc: 0.024.\n",
            "Epoch [1/10]. Step [120/120]. Loss: 0.028. Test acc: 0.022.\n",
            "Epoch [2/10]. Step [1/120]. Loss: 0.025. Test acc: 0.021.\n",
            "Epoch [2/10]. Step [101/120]. Loss: 0.025. Test acc: 0.014.\n",
            "Epoch [2/10]. Step [120/120]. Loss: 0.021. Test acc: 0.013.\n",
            "Epoch [3/10]. Step [1/120]. Loss: 0.021. Test acc: 0.013.\n",
            "Epoch [3/10]. Step [101/120]. Loss: 0.018. Test acc: 0.010.\n",
            "Epoch [3/10]. Step [120/120]. Loss: 0.016. Test acc: 0.010.\n",
            "Epoch [4/10]. Step [1/120]. Loss: 0.014. Test acc: 0.010.\n",
            "Epoch [4/10]. Step [101/120]. Loss: 0.014. Test acc: 0.008.\n",
            "Epoch [4/10]. Step [120/120]. Loss: 0.013. Test acc: 0.008.\n",
            "Epoch [5/10]. Step [1/120]. Loss: 0.011. Test acc: 0.008.\n",
            "Epoch [5/10]. Step [101/120]. Loss: 0.012. Test acc: 0.007.\n",
            "Epoch [5/10]. Step [120/120]. Loss: 0.011. Test acc: 0.008.\n",
            "Epoch [6/10]. Step [1/120]. Loss: 0.009. Test acc: 0.008.\n",
            "Epoch [6/10]. Step [101/120]. Loss: 0.010. Test acc: 0.007.\n",
            "Epoch [6/10]. Step [120/120]. Loss: 0.009. Test acc: 0.007.\n",
            "Epoch [7/10]. Step [1/120]. Loss: 0.009. Test acc: 0.007.\n",
            "Epoch [7/10]. Step [101/120]. Loss: 0.009. Test acc: 0.007.\n",
            "Epoch [7/10]. Step [120/120]. Loss: 0.009. Test acc: 0.007.\n",
            "Epoch [8/10]. Step [1/120]. Loss: 0.008. Test acc: 0.007.\n",
            "Epoch [8/10]. Step [101/120]. Loss: 0.008. Test acc: 0.007.\n",
            "Epoch [8/10]. Step [120/120]. Loss: 0.008. Test acc: 0.006.\n",
            "Epoch [9/10]. Step [1/120]. Loss: 0.011. Test acc: 0.006.\n",
            "Epoch [9/10]. Step [101/120]. Loss: 0.008. Test acc: 0.006.\n",
            "Epoch [9/10]. Step [120/120]. Loss: 0.008. Test acc: 0.006.\n",
            "Epoch [10/10]. Step [1/120]. Loss: 0.009. Test acc: 0.006.\n",
            "Epoch [10/10]. Step [101/120]. Loss: 0.008. Test acc: 0.006.\n",
            "Epoch [10/10]. Step [120/120]. Loss: 0.008. Test acc: 0.006.\n",
            "Best acc train: 0.992. Best acc test: 0.992\n",
            "Training is finished!\n",
            "CPU times: user 10.4 s, sys: 2.77 s, total: 13.2 s\n",
            "Wall time: 24.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RMSProp + momentum"
      ],
      "metadata": {
        "id": "pw7kR1jV5Ome"
      },
      "id": "pw7kR1jV5Ome"
    },
    {
      "cell_type": "code",
      "source": [
        "net = CHNet()\n",
        "optimizer = RMSprop(net.parameters(), lr=LR, momentum=0.98)"
      ],
      "metadata": {
        "id": "-RSp4_765Ph6"
      },
      "id": "-RSp4_765Ph6",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_loop(train_loader, test_loader, net, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LjiZ61z5XAq",
        "outputId": "4432a3e2-c5a1-4e09-cf9f-67b55dbbbdf1"
      },
      "id": "3LjiZ61z5XAq",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]. Step [1/120]. Loss: 0.041. Test acc: 0.040.\n",
            "Epoch [1/10]. Step [101/120]. Loss: 0.014. Test acc: 0.008.\n",
            "Epoch [1/10]. Step [120/120]. Loss: 0.009. Test acc: 0.007.\n",
            "Epoch [2/10]. Step [1/120]. Loss: 0.010. Test acc: 0.007.\n",
            "Epoch [2/10]. Step [101/120]. Loss: 0.007. Test acc: 0.005.\n",
            "Epoch [2/10]. Step [120/120]. Loss: 0.006. Test acc: 0.005.\n",
            "Epoch [3/10]. Step [1/120]. Loss: 0.007. Test acc: 0.005.\n",
            "Epoch [3/10]. Step [101/120]. Loss: 0.006. Test acc: 0.005.\n",
            "Epoch [3/10]. Step [120/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [4/10]. Step [1/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [4/10]. Step [101/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [4/10]. Step [120/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [5/10]. Step [1/120]. Loss: 0.006. Test acc: 0.005.\n",
            "Epoch [5/10]. Step [101/120]. Loss: 0.005. Test acc: 0.004.\n",
            "Epoch [5/10]. Step [120/120]. Loss: 0.005. Test acc: 0.004.\n",
            "Epoch [6/10]. Step [1/120]. Loss: 0.006. Test acc: 0.004.\n",
            "Epoch [6/10]. Step [101/120]. Loss: 0.005. Test acc: 0.004.\n",
            "Epoch [6/10]. Step [120/120]. Loss: 0.005. Test acc: 0.004.\n",
            "Epoch [7/10]. Step [1/120]. Loss: 0.005. Test acc: 0.004.\n",
            "Epoch [7/10]. Step [101/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [7/10]. Step [120/120]. Loss: 0.005. Test acc: 0.004.\n",
            "Epoch [8/10]. Step [1/120]. Loss: 0.006. Test acc: 0.005.\n",
            "Epoch [8/10]. Step [101/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [8/10]. Step [120/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [9/10]. Step [1/120]. Loss: 0.003. Test acc: 0.005.\n",
            "Epoch [9/10]. Step [101/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [9/10]. Step [120/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [10/10]. Step [1/120]. Loss: 0.004. Test acc: 0.005.\n",
            "Epoch [10/10]. Step [101/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [10/10]. Step [120/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Best acc train: 0.997. Best acc test: 0.996\n",
            "Training is finished!\n",
            "CPU times: user 10.5 s, sys: 2.7 s, total: 13.2 s\n",
            "Wall time: 18.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adam"
      ],
      "metadata": {
        "id": "5VFMVGtl5e6N"
      },
      "id": "5VFMVGtl5e6N"
    },
    {
      "cell_type": "code",
      "source": [
        "net = CHNet()\n",
        "optimizer = Adam(net.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "3L5SAVUx5m35"
      },
      "id": "3L5SAVUx5m35",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_loop(train_loader, test_loader, net, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3rnpgMh5poy",
        "outputId": "10134062-27f5-4714-b657-c3bdce0c0f67"
      },
      "id": "A3rnpgMh5poy",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]. Step [1/120]. Loss: 0.033. Test acc: 0.043.\n",
            "Epoch [1/10]. Step [101/120]. Loss: 0.028. Test acc: 0.013.\n",
            "Epoch [1/10]. Step [120/120]. Loss: 0.023. Test acc: 0.012.\n",
            "Epoch [2/10]. Step [1/120]. Loss: 0.024. Test acc: 0.012.\n",
            "Epoch [2/10]. Step [101/120]. Loss: 0.020. Test acc: 0.010.\n",
            "Epoch [2/10]. Step [120/120]. Loss: 0.017. Test acc: 0.010.\n",
            "Epoch [3/10]. Step [1/120]. Loss: 0.017. Test acc: 0.010.\n",
            "Epoch [3/10]. Step [101/120]. Loss: 0.015. Test acc: 0.009.\n",
            "Epoch [3/10]. Step [120/120]. Loss: 0.013. Test acc: 0.009.\n",
            "Epoch [4/10]. Step [1/120]. Loss: 0.014. Test acc: 0.009.\n",
            "Epoch [4/10]. Step [101/120]. Loss: 0.012. Test acc: 0.008.\n",
            "Epoch [4/10]. Step [120/120]. Loss: 0.011. Test acc: 0.007.\n",
            "Epoch [5/10]. Step [1/120]. Loss: 0.009. Test acc: 0.007.\n",
            "Epoch [5/10]. Step [101/120]. Loss: 0.009. Test acc: 0.007.\n",
            "Epoch [5/10]. Step [120/120]. Loss: 0.009. Test acc: 0.007.\n",
            "Epoch [6/10]. Step [1/120]. Loss: 0.009. Test acc: 0.006.\n",
            "Epoch [6/10]. Step [101/120]. Loss: 0.008. Test acc: 0.006.\n",
            "Epoch [6/10]. Step [120/120]. Loss: 0.008. Test acc: 0.006.\n",
            "Epoch [7/10]. Step [1/120]. Loss: 0.008. Test acc: 0.006.\n",
            "Epoch [7/10]. Step [101/120]. Loss: 0.007. Test acc: 0.006.\n",
            "Epoch [7/10]. Step [120/120]. Loss: 0.007. Test acc: 0.005.\n",
            "Epoch [8/10]. Step [1/120]. Loss: 0.005. Test acc: 0.006.\n",
            "Epoch [8/10]. Step [101/120]. Loss: 0.007. Test acc: 0.005.\n",
            "Epoch [8/10]. Step [120/120]. Loss: 0.006. Test acc: 0.005.\n",
            "Epoch [9/10]. Step [1/120]. Loss: 0.006. Test acc: 0.005.\n",
            "Epoch [9/10]. Step [101/120]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [9/10]. Step [120/120]. Loss: 0.006. Test acc: 0.005.\n",
            "Epoch [10/10]. Step [1/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [10/10]. Step [101/120]. Loss: 0.006. Test acc: 0.005.\n",
            "Epoch [10/10]. Step [120/120]. Loss: 0.006. Test acc: 0.005.\n",
            "Best acc train: 0.995. Best acc test: 0.995\n",
            "Training is finished!\n",
            "CPU times: user 11.4 s, sys: 2.56 s, total: 13.9 s\n",
            "Wall time: 18.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение моделей с lr = 0.01\n"
      ],
      "metadata": {
        "id": "ZEQDVqId6ZZ5"
      },
      "id": "ZEQDVqId6ZZ5"
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHES = 10\n",
        "LR = 0.01"
      ],
      "metadata": {
        "id": "n34HMRzl5r4C"
      },
      "id": "n34HMRzl5r4C",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SGD"
      ],
      "metadata": {
        "id": "-NhphQ_N6jTI"
      },
      "id": "-NhphQ_N6jTI"
    },
    {
      "cell_type": "code",
      "source": [
        "net = CHNet()\n",
        "optimizer = SGD(net.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "PAe_Qafv6jTJ"
      },
      "execution_count": 25,
      "outputs": [],
      "id": "PAe_Qafv6jTJ"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_loop(train_loader, test_loader, net, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dad93de-cf47-4225-f24c-fc48fd2b29a7",
        "id": "iyuIMj-y6jTK"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]. Step [1/120]. Loss: 0.031. Test acc: 0.038.\n",
            "Epoch [1/10]. Step [101/120]. Loss: 0.021. Test acc: 0.009.\n",
            "Epoch [1/10]. Step [120/120]. Loss: 0.011. Test acc: 0.009.\n",
            "Epoch [2/10]. Step [1/120]. Loss: 0.009. Test acc: 0.010.\n",
            "Epoch [2/10]. Step [101/120]. Loss: 0.009. Test acc: 0.008.\n",
            "Epoch [2/10]. Step [120/120]. Loss: 0.008. Test acc: 0.009.\n",
            "Epoch [3/10]. Step [1/120]. Loss: 0.006. Test acc: 0.009.\n",
            "Epoch [3/10]. Step [101/120]. Loss: 0.008. Test acc: 0.007.\n",
            "Epoch [3/10]. Step [120/120]. Loss: 0.008. Test acc: 0.007.\n",
            "Epoch [4/10]. Step [1/120]. Loss: 0.005. Test acc: 0.008.\n",
            "Epoch [4/10]. Step [101/120]. Loss: 0.007. Test acc: 0.007.\n",
            "Epoch [4/10]. Step [120/120]. Loss: 0.007. Test acc: 0.007.\n",
            "Epoch [5/10]. Step [1/120]. Loss: 0.007. Test acc: 0.007.\n",
            "Epoch [5/10]. Step [101/120]. Loss: 0.006. Test acc: 0.007.\n",
            "Epoch [5/10]. Step [120/120]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [6/10]. Step [1/120]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [6/10]. Step [101/120]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [6/10]. Step [120/120]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [7/10]. Step [1/120]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [7/10]. Step [101/120]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [7/10]. Step [120/120]. Loss: 0.005. Test acc: 0.006.\n",
            "Epoch [8/10]. Step [1/120]. Loss: 0.005. Test acc: 0.006.\n",
            "Epoch [8/10]. Step [101/120]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [8/10]. Step [120/120]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [9/10]. Step [1/120]. Loss: 0.007. Test acc: 0.006.\n",
            "Epoch [9/10]. Step [101/120]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [9/10]. Step [120/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [10/10]. Step [1/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [10/10]. Step [101/120]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [10/10]. Step [120/120]. Loss: 0.006. Test acc: 0.005.\n",
            "Best acc train: 0.995. Best acc test: 0.995\n",
            "Training is finished!\n",
            "CPU times: user 9.68 s, sys: 2.68 s, total: 12.4 s\n",
            "Wall time: 18.2 s\n"
          ]
        }
      ],
      "id": "iyuIMj-y6jTK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "RMSProp + momentum"
      ],
      "metadata": {
        "id": "xCwg5YcO6w5B"
      },
      "id": "xCwg5YcO6w5B"
    },
    {
      "cell_type": "code",
      "source": [
        "net = CHNet()\n",
        "optimizer = RMSprop(net.parameters(), lr=LR, momentum=0.98)"
      ],
      "metadata": {
        "id": "OhgELtfR6w5C"
      },
      "execution_count": 27,
      "outputs": [],
      "id": "OhgELtfR6w5C"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_loop(train_loader, test_loader, net, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0aaa80f-6a54-407a-92eb-da9aa3416428",
        "id": "2vLciyZd6w5C"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]. Step [1/120]. Loss: 0.037. Test acc: 0.045.\n",
            "Epoch [1/10]. Step [101/120]. Loss: 0.014. Test acc: 0.009.\n",
            "Epoch [1/10]. Step [120/120]. Loss: 0.011. Test acc: 0.009.\n",
            "Epoch [2/10]. Step [1/120]. Loss: 0.009. Test acc: 0.009.\n",
            "Epoch [2/10]. Step [101/120]. Loss: 0.008. Test acc: 0.006.\n",
            "Epoch [2/10]. Step [120/120]. Loss: 0.007. Test acc: 0.007.\n",
            "Epoch [3/10]. Step [1/120]. Loss: 0.009. Test acc: 0.007.\n",
            "Epoch [3/10]. Step [101/120]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [3/10]. Step [120/120]. Loss: 0.006. Test acc: 0.005.\n",
            "Epoch [4/10]. Step [1/120]. Loss: 0.006. Test acc: 0.004.\n",
            "Epoch [4/10]. Step [101/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [4/10]. Step [120/120]. Loss: 0.005. Test acc: 0.004.\n",
            "Epoch [5/10]. Step [1/120]. Loss: 0.006. Test acc: 0.004.\n",
            "Epoch [5/10]. Step [101/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [5/10]. Step [120/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [6/10]. Step [1/120]. Loss: 0.007. Test acc: 0.005.\n",
            "Epoch [6/10]. Step [101/120]. Loss: 0.005. Test acc: 0.004.\n",
            "Epoch [6/10]. Step [120/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [7/10]. Step [1/120]. Loss: 0.004. Test acc: 0.005.\n",
            "Epoch [7/10]. Step [101/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [7/10]. Step [120/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [8/10]. Step [1/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [8/10]. Step [101/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [8/10]. Step [120/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [9/10]. Step [1/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [9/10]. Step [101/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [9/10]. Step [120/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [10/10]. Step [1/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [10/10]. Step [101/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [10/10]. Step [120/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Best acc train: 0.996. Best acc test: 0.996\n",
            "Training is finished!\n",
            "CPU times: user 10.7 s, sys: 2.72 s, total: 13.4 s\n",
            "Wall time: 18.9 s\n"
          ]
        }
      ],
      "id": "2vLciyZd6w5C"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adam"
      ],
      "metadata": {
        "id": "2Gvb0jir6w5D"
      },
      "id": "2Gvb0jir6w5D"
    },
    {
      "cell_type": "code",
      "source": [
        "net = CHNet()\n",
        "optimizer = Adam(net.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "9r6lsVkl6w5D"
      },
      "execution_count": 29,
      "outputs": [],
      "id": "9r6lsVkl6w5D"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_loop(train_loader, test_loader, net, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd31363-a5d8-43ae-f4a4-16f36c6b4a5e",
        "id": "OVTxaHdd6w5E"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]. Step [1/120]. Loss: 0.043. Test acc: 0.041.\n",
            "Epoch [1/10]. Step [101/120]. Loss: 0.019. Test acc: 0.008.\n",
            "Epoch [1/10]. Step [120/120]. Loss: 0.010. Test acc: 0.007.\n",
            "Epoch [2/10]. Step [1/120]. Loss: 0.010. Test acc: 0.007.\n",
            "Epoch [2/10]. Step [101/120]. Loss: 0.007. Test acc: 0.005.\n",
            "Epoch [2/10]. Step [120/120]. Loss: 0.006. Test acc: 0.005.\n",
            "Epoch [3/10]. Step [1/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [3/10]. Step [101/120]. Loss: 0.006. Test acc: 0.005.\n",
            "Epoch [3/10]. Step [120/120]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [4/10]. Step [1/120]. Loss: 0.006. Test acc: 0.005.\n",
            "Epoch [4/10]. Step [101/120]. Loss: 0.006. Test acc: 0.005.\n",
            "Epoch [4/10]. Step [120/120]. Loss: 0.005. Test acc: 0.006.\n",
            "Epoch [5/10]. Step [1/120]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [5/10]. Step [101/120]. Loss: 0.005. Test acc: 0.006.\n",
            "Epoch [5/10]. Step [120/120]. Loss: 0.005. Test acc: 0.006.\n",
            "Epoch [6/10]. Step [1/120]. Loss: 0.005. Test acc: 0.006.\n",
            "Epoch [6/10]. Step [101/120]. Loss: 0.005. Test acc: 0.007.\n",
            "Epoch [6/10]. Step [120/120]. Loss: 0.005. Test acc: 0.006.\n",
            "Epoch [7/10]. Step [1/120]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [7/10]. Step [101/120]. Loss: 0.005. Test acc: 0.006.\n",
            "Epoch [7/10]. Step [120/120]. Loss: 0.005. Test acc: 0.006.\n",
            "Epoch [8/10]. Step [1/120]. Loss: 0.004. Test acc: 0.006.\n",
            "Epoch [8/10]. Step [101/120]. Loss: 0.005. Test acc: 0.007.\n",
            "Epoch [8/10]. Step [120/120]. Loss: 0.005. Test acc: 0.007.\n",
            "Epoch [9/10]. Step [1/120]. Loss: 0.006. Test acc: 0.007.\n",
            "Epoch [9/10]. Step [101/120]. Loss: 0.005. Test acc: 0.006.\n",
            "Epoch [9/10]. Step [120/120]. Loss: 0.005. Test acc: 0.006.\n",
            "Epoch [10/10]. Step [1/120]. Loss: 0.005. Test acc: 0.006.\n",
            "Epoch [10/10]. Step [101/120]. Loss: 0.005. Test acc: 0.007.\n",
            "Epoch [10/10]. Step [120/120]. Loss: 0.005. Test acc: 0.006.\n",
            "Best acc train: 0.996. Best acc test: 0.995\n",
            "Training is finished!\n",
            "CPU times: user 11.8 s, sys: 2.75 s, total: 14.5 s\n",
            "Wall time: 19.5 s\n"
          ]
        }
      ],
      "id": "OVTxaHdd6w5E"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Структура модели:\n",
        "* 4 скрытых посносвязных слоя + 1 выходной слой\n",
        "* в качестве функии активации во всех слоях бла применена LeakyRelu\n",
        "* на каждом слое применён Dropout 0.5\n",
        "* во всех слоях перед функцией активации применена батч-нормализация\n",
        "\n",
        "Выводы:\n",
        "\n",
        "Модели были обучены с исспользованием оптимизаторов Adam, SGD, RMSProp. Lr составил в 0,002 и 0,01 для епрвого и второго прогона моделей. На данном наборе данных и выбранной архитектурой модели значимого различия между оптимизаторами и скоростью обучения не выявлено.\n",
        "\n",
        "В каждом случае модели показывали отличные результаты как на тренировочных данных  так и на тестовых.\n",
        "\n",
        "Наилучший результат был достигнут с применением RMSProp (lr=0.02, momentum=0.98) с разницей в 0,001 по сравнению с другими оптимизаторами.\n"
      ],
      "metadata": {
        "id": "i10yvIzt7lNL"
      },
      "id": "i10yvIzt7lNL"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}